{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models import GatedAdditiveTreeEnsembleConfig\n",
    "from pytorch_tabular import TabularModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"dataset\": \"Ailerons\",\n",
    "        \"n_trials\": 100,\n",
    "        \"batch_size\": 512,\n",
    "        \"max_epochs\": 100,\n",
    "        \"early_stopping_patience\": 10,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"strategy\": \"tpe\",\n",
    "        \"pruning\": False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = DATA_DIR / config[\"dataset\"]\n",
    "d_config_files = list(data_path.glob(\"*config*\"))\n",
    "d_config = np.load(d_config_files[0], allow_pickle=True).item()\n",
    "task = \"classification\" if d_config[\"regression\"] == 0 else \"regression\"\n",
    "n_folds = len(d_config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = np.load(\n",
    "    data_path / \"x_test_fold_0.npy\", allow_pickle=True\n",
    ").shape[1]\n",
    "cat_col_names = None\n",
    "num_col_names = [f\"feature_{i}\" for i in range(n_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\"target\"],\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names or [],\n",
    "    normalize_continuous_features=True,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,  # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    early_stopping=\"valid_loss\",\n",
    "    early_stopping_mode=\"min\",  # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=config[\n",
    "        \"early_stopping_patience\"\n",
    "    ],  # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\",\n",
    "    load_best=True,  # After training, load the best checkpoint\n",
    "    # progress_bar=\"none\",  # Turning off Progress bar\n",
    "    # trainer_kwargs=dict(enable_model_summary=False),  # Turning off model summary\n",
    ")\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=config[\"optimizer\"], optimizer_params={\"weight_decay\": 1e-7}\n",
    ")\n",
    "model_config = GatedAdditiveTreeEnsembleConfig(\n",
    "    task=task,\n",
    "    learning_rate=0.001,\n",
    "    metrics=[\"r2_score\"] if task == \"regression\" else None,\n",
    "    metrics_prob_input=[False] if task == \"regression\" else None,\n",
    "    gflu_stages=17,\n",
    "    gflu_dropout=0.17,\n",
    "    gflu_feature_init_sparsity=0.21,\n",
    "    learnable_sparsity=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 13:34:47,963 - {pytorch_tabular.tabular_model:105} - INFO - Experiment Tracking is turned off\n",
      "Global seed set to 42\n",
      "2023-06-11 13:34:47,983 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-06-11 13:34:47,984 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-06-11 13:34:48,002 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: GatedAdditiveTreeEnsembleModel\n",
      "2023-06-11 13:34:48,045 - {pytorch_tabular.models.gate.gate_model:282} - INFO - Data Aware Initialization of T0\n",
      "2023-06-11 13:34:48,067 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-06-11 13:34:48,098 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:604: UserWarning: Checkpoint directory C:\\Work\\Completed Research\\gate_v2_experimentation\\saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GatedAdditiveTreesBackbone │  197 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer           │     66 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ CustomHead                 │     28 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                    │      0 │\n",
       "└───┴──────────────────┴────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GatedAdditiveTreesBackbone │  197 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer           │     66 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ CustomHead                 │     28 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                    │      0 │\n",
       "└───┴──────────────────┴────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 197 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 197 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 197 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 197 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddf6a6c3fa541518f4ecaca91cf9be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 13:39:15,537 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-06-11 13:39:15,538 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\manuj\\miniconda3\\envs\\gate\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73771208cb34b35a311f057e7bc1daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "metrics = []\n",
    "for fold in range(n_folds):\n",
    "    x_train = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"x_train_fold_{fold}.npy\", allow_pickle=True\n",
    "    )\n",
    "    y_train = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"y_train_fold_{fold}.npy\", allow_pickle=True\n",
    "    ).reshape(-1, 1)\n",
    "    x_val = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"x_val_fold_{fold}.npy\", allow_pickle=True\n",
    "    )\n",
    "    y_val = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"y_val_fold_{fold}.npy\", allow_pickle=True\n",
    "    ).reshape(-1, 1)\n",
    "    x_test = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"x_train_fold_{fold}.npy\", allow_pickle=True\n",
    "    )\n",
    "    y_test = np.load(\n",
    "        DATA_DIR/\"Ailerons\" / f\"y_train_fold_{fold}.npy\", allow_pickle=True\n",
    "    ).reshape(-1, 1)\n",
    "    # combine x and y into a dataframe\n",
    "    train = pd.DataFrame(\n",
    "        np.concatenate([x_train, y_train], axis=1),\n",
    "        columns=[f\"feature_{i}\" for i in range(x_train.shape[1])]\n",
    "        + [\"target\"],\n",
    "    )\n",
    "    val = pd.DataFrame(\n",
    "        np.concatenate([x_val, y_val], axis=1),\n",
    "        columns=[f\"feature_{i}\" for i in range(x_val.shape[1])] + [\"target\"],\n",
    "    )\n",
    "    test = pd.DataFrame(\n",
    "        np.concatenate([x_test, y_test], axis=1),\n",
    "        columns=[f\"feature_{i}\" for i in range(x_test.shape[1])] + [\"target\"],\n",
    "    )\n",
    "    # Initialize the tabular model\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "    )\n",
    "    try:\n",
    "        # Fit the model\n",
    "        tabular_model.fit(\n",
    "            train=train,\n",
    "            validation=val,\n",
    "            target_transform=(lambda x: x*1000, lambda x: x/1000)\n",
    "            # callbacks=[\n",
    "            #     PyTorchLightningPruningCallback(trial, monitor=\"valid_loss\")\n",
    "            # ],\n",
    "        )\n",
    "        result = tabular_model.evaluate(test, verbose=False)\n",
    "        metrics.append(result[0][\"test_r2_score\"])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        # gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        metrics.append(0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.02455640397965908, 'test_r2_score': 0.8540627956390381}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.87528306"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['target']*1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
